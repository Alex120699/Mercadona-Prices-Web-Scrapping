import sqlite3
import re
import json
import streamlit as st
import ollama
from scripts.db_utils import get_db_connection
from typing import Dict, List, Optional, Tuple
import unicodedata

# ---------------------------
# CONSTANTES
# ---------------------------
MODELS = [
        'llama3.2',
        'gemma3',
        'phi3',
        'deepseek-r1',
        'llama2-uncensored',
        'mistral',
        'qwen2.5',
        'deepseek-r1:8b',
        'llama3.1',
        'gemma2',
        'gemma3:12b',
        'deepseek-r1:14b',
        'phi3:14b',
        'qwen2.5:14b',
        'qwen2.5:14b-instruct-q3_K_M',
        'gemma3:27b',
        'deepseek-r1:32b'
]

# Niveles de categor√≠a
CAT_LEVELS = ['L1', 'L2', 'L3']

# ---------------------------
# FUNCIONES DE NORMALIZACI√ìN
# ---------------------------
def normalizar_texto(texto: str) -> str:
    """Normaliza texto para comparaci√≥n eliminando tildes y convirtiendo a min√∫sculas"""
    if not texto:
        return ""
    # Normaliza a forma NFKD (descompone tildes y caracteres)
    texto = unicodedata.normalize('NFKD', texto.lower())
    # Elimina los caracteres de combinaci√≥n (tildes)
    texto = texto.encode('ascii', 'ignore').decode('ascii')
    return texto


def normalizar_categorias(categorias: Dict) -> Dict:
    """Normaliza todas las categor√≠as en la estructura"""
    return {
        normalizar_texto(l1): {
            normalizar_texto(l2): [normalizar_texto(l3) for l3 in l3s]
            for l2, l3s in l2s.items()
        }
        for l1, l2s in categorias.items()
    }




# ---------------------------
# FUNCIONES DE BASE DE DATOS
# ---------------------------
def get_products():
    """Obtiene todos los productos de la base de datos"""
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("SELECT id, nombre FROM productos")
    products = {row[0]: row[1] for row in cursor.fetchall()}
    conn.close()
    return products

def obtener_categorias():
    """Extrae todas las categor√≠as L1, L2 y L3 desde la base de datos"""
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("SELECT DISTINCT LOWER(categoria_L1), LOWER(categoria_L2), LOWER(categoria_L3) FROM productos")
    
    categorias = {}
    for l1, l2, l3 in cursor.fetchall():
        categorias.setdefault(l1, {}).setdefault(l2, []).append(l3)
    
    conn.close()
    return categorias

def obtener_productos_por_categoria(categoria_l1: str, categoria_l2: str, categoria_l3: str) -> Dict:
    """Obtiene productos de una categor√≠a L3 espec√≠fica con manejo de tildes"""
    conn = get_db_connection()
    cursor = conn.cursor()

    # Normalizamos las categor√≠as para comparaci√≥n
    cat_l1_norm = normalizar_texto(categoria_l1)
    cat_l2_norm = normalizar_texto(categoria_l2)
    cat_l3_norm = normalizar_texto(categoria_l3)

    # Consulta con condiciones normalizadas
    cursor.execute("""
        SELECT id, nombre, packaging, unit_size, size_format, precio_con_descuento, bulk_price
        FROM productos 
        WHERE 
            LOWER(REPLACE(REPLACE(REPLACE(categoria_L1, '√°', 'a'), '√©', 'e'), '√≠', 'i')) = ? 
            AND LOWER(REPLACE(REPLACE(REPLACE(categoria_L2, '√°', 'a'), '√©', 'e'), '√≠', 'i')) = ? 
            AND LOWER(REPLACE(REPLACE(REPLACE(categoria_L3, '√°', 'a'), '√©', 'e'), '√≠', 'i')) = ?
    """, (cat_l1_norm, cat_l2_norm, cat_l3_norm))

    productos = {
        str(row['id']): {
            "nombre": row['nombre'],
            "packaging": row['packaging'],
            "unit_size": row['unit_size'],
            "size_format": row['size_format'],
            "price": row["precio_con_descuento"],
            "price_per_unit_of_measure": row["bulk_price"]
        } for row in cursor.fetchall()
    }
    
    conn.close()
    return productos

def obtener_info_producto(product_id):
    """Obtiene toda la informaci√≥n de un producto espec√≠fico"""
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("SELECT * FROM productos WHERE id = ?", (product_id,))
    resultado = dict(cursor.fetchone()) if cursor.fetchone() else None
    conn.close()
    return resultado

def obtener_categorias_normalizadas() -> Dict:
    """Obtiene categor√≠as ya normalizadas desde la base de datos"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    cursor.execute("""
        SELECT DISTINCT 
            categoria_L1, 
            categoria_L2, 
            categoria_L3 
        FROM productos
    """)
    
    categorias = {}
    for l1, l2, l3 in cursor.fetchall():
        l1_norm = normalizar_texto(l1)
        l2_norm = normalizar_texto(l2)
        l3_norm = normalizar_texto(l3)
        
        if l1_norm not in categorias:
            categorias[l1_norm] = {}
        if l2_norm not in categorias[l1_norm]:
            categorias[l1_norm][l2_norm] = []
        if l3_norm not in categorias[l1_norm][l2_norm]:
            categorias[l1_norm][l2_norm].append(l3_norm)
    
    conn.close()
    return categorias



# ---------------------------
# FUNCIONES DE PROCESAMIENTO LLM
# ---------------------------
def clasificar_categoria_llm(query, categorias, model, nivel="L1"):
    """Clasifica la b√∫squeda en categor√≠as usando LLM"""
    prompt = f"""
    El usuario busca: "{query.lower()}".

    Categor√≠as disponibles para {nivel}:
    {", ".join([c.lower() for c in categorias])}

    Devuelve solo una categor√≠a en formato: {{"{nivel}": "nombre_de_categoria"}}.
    """
    print("PROMPT: \n\n",prompt)
    respuesta = ollama.chat(model=model, messages=[{"role": "user", "content": prompt}])
    return limpiar_respuesta_json(respuesta["message"]["content"])[nivel]

def buscar_similares(query, model):
    """Ejecuta el pipeline completo de b√∫squeda de productos similares"""
    categorias = obtener_categorias()
    
    # Clasificaci√≥n jer√°rquica
    l1 = clasificar_categoria_llm(query, list(categorias.keys()), model, "L1")
    l2 = clasificar_categoria_llm(query, list(categorias[l1].keys()), model, "L2")
    l3 = clasificar_categoria_llm(query, categorias[l1][l2], model, "L3")

    return obtener_productos_por_categoria(l1, l2, l3)

def analizar_productos(query: str, productos: Dict, model: str) -> str:
    """
    Genera un an√°lisis comparativo completo de los productos sin elegir uno espec√≠fico.
    
    Args:
        query: B√∫squeda original del usuario
        productos: Diccionario completo de productos {id: {info}}
        model: Modelo de LLM a usar
        
    Returns:
        str: An√°lisis comparativo detallado en formato de texto
    """
    prompt = f"""
    Eres un experto en an√°lisis comparativo de productos de supermercado. 
    El usuario busc√≥: "{query}"

    Estos son los productos disponibles:
    {json.dumps(productos, indent=2, ensure_ascii=False)}

    Genera un an√°lisis que:
    1. Compare objetivamente las caracter√≠sticas clave (nombre, packaging, tama√±o)
    2. Destaque las diferencias relevantes
    3. Mencione casos de uso ideales para cada opci√≥n
    4. No elijas un "mejor" producto
    5. Usa un tono profesional pero claro

    Formato esperado:
    '''
    [Introducci√≥n general sobre los productos encontrados]

    - [Nombre Producto 1]:
      * Caracter√≠sticas: [packaging], [tama√±o]
      * Ideal para: [casos de uso]
      * Notas: [observaciones relevantes]

    - [Nombre Producto 2]:
      * Caracter√≠sticas: [packaging], [tama√±o]
      * Ideal para: [casos de use]
      * Notas: [observaciones relevantes]

    [Conclusi√≥n comparativa general]
    '''
    """
    
    respuesta = ollama.chat(
        model=model,
        messages=[{"role": "user", "content": prompt}],
        options={"temperature": 0.5}
    )
    
    return respuesta["message"]["content"].strip()

def generar_resumen(query: str, productos: Dict, analisis: str, model: str) -> str:
    """
    Genera una respuesta final integrando el an√°lisis con los datos completos.
    
    Args:
        query: B√∫squeda original
        productos: Diccionario completo de productos
        analisis: Texto generado por analizar_productos()
        model: Modelo de LLM a usar
        
    Returns:
        str: Recomendaci√≥n completa con formato
    """
    # Preparamos datos estructurados para el prompt
    datos_productos = "\n".join(
        f"- {info['nombre']} (ID: {id}): "
        f"{info['packaging']} de {info['unit_size']}{info['size_format']}, "
        f"Precio: {info['price']}‚Ç¨, "
        f"Precio/{info["size_format"]}: {info["price_per_unit_of_measure"]}‚Ç¨"
        for id, info in productos.items()
    )

    prompt = f"""
    Bas√°ndote en este an√°lisis comparativo previo:
    {analisis}

    Y en los datos completos de los productos:
    {datos_productos}

    Genera una respuesta final para el usuario que:
    1. Comience con un resumen ejecutivo de las opciones
    2. Integre naturalmente el an√°lisis comparativo
    3. Incluya informaci√≥n de precios (si est√° disponible)
    4. Mantenga un tono √∫til y objetivo
    5. Use este formato:

    **Resumen para "{query}"**  
    [Introducci√≥n general]  

    **Opciones disponibles:**  
    [An√°lisis integrado con datos reales]  

    **Conclusi√≥n:**  
    [Recomendaciones de uso generales sin favorecer un producto espec√≠fico]  
    """
    
    respuesta = ollama.chat(
        model=model,
        messages=[{"role": "user", "content": prompt}]
    )
    
    return respuesta["message"]["content"].strip()


def generar_prompt_clasificacion(
    query: str, 
    opciones: List[str], 
    nivel: str
) -> str:
    """Genera un prompt optimizado para clasificaci√≥n de categor√≠as"""
    return f"""
    TAREA: Clasificar una b√∫squeda de producto en una categor√≠a espec√≠fica.

    INSTRUCCIONES:
    1. Analiza la b√∫squeda: "{query}"
    2. Selecciona la categor√≠a {nivel} M√ÅS APROPIADA
    3. DEBES usar EXACTAMENTE uno de estos nombres (sin modificar):
    {", ".join(opciones)}

    REGLAS:
    - Respuesta SOLO en formato: {{"{nivel}": "nombre_exacto"}}
    - No inventes categor√≠as
    - Si no est√° claro, elige la m√°s gen√©rica
    - Considera sin√≥nimos y variaciones ling√º√≠sticas

    EJEMPLO: Si la categor√≠a es "bebidas" y el usuario busca "refresco", 
    debes devolver "bebidas"
    """

def filtrar_productos_relevantes(query: str, productos: Dict, model: str) -> Dict:
    """
    Filtra los productos manteniendo solo los que realmente coinciden con la b√∫squeda.
    
    Args:
        query: T√©rmino de b√∫squeda original
        productos: Diccionario completo de productos {id: {info}}
        model: Modelo LLM a usar
        
    Returns:
        Dict: Subconjunto de productos relevantes
    """
    prompt = f"""
    Eres un filtro inteligente de productos. Analiza esta b√∫squeda y lista de productos:
    
    B√öSQUEDA ORIGINAL: "{query}"
    
    PRODUCTOS EN CATEGOR√çA (formato JSON):
    {json.dumps(productos, indent=2, ensure_ascii=False)}
    
    TAREA:
    1. Identifica qu√© productos coinciden REALMENTE con la b√∫squeda
    2. Excluye productos que sean de otra categor√≠a aunque est√©n en el mismo grupo L3
    3. Considera sin√≥nimos y variaciones ling√º√≠sticas
    
    RESPONDE en formato JSON con este esquema:
    {{
        "productos_relevantes": {{
            "id_producto": {{
                "nombre": "str",
                "match_score": float (0-1),
                "razon": "str"
            }}
        }},
        "exclusiones": {{
            "id_producto": "raz√≥n_de_exclusi√≥n"
        }}
    }}
    """
    
    respuesta = ollama.chat(
        model=model,
        messages=[{"role": "user", "content": prompt}],
        options={"temperature": 0.2}
    )
    
    try:
        resultado = json.loads(respuesta["message"]["content"])
        return {
            id: productos[id] 
            for id in resultado["productos_relevantes"]
            if id in productos
        }
    except:
        return productos  # Fallback si hay error

def generar_resumen_focalizado(query: str, productos_filtrados: Dict, model: str) -> str:
    """
    Genera un resumen exclusivo sobre los productos relevantes.
    
    Args:
        query: B√∫squeda original
        productos_filtrados: Diccionario ya filtrado
        model: Modelo LLM a usar
        
    Returns:
        str: Resumen en formato Markdown
    """
    if not productos_filtrados:
        return "No encontr√© productos que coincidan exactamente con tu b√∫squeda."
    
    prompt = f"""
    Eres un asistente de supermercado. Genera un resumen SOBRE LOS PRODUCTOS QUE COINCIDEN EXACTAMENTE con esta b√∫squeda:
    
    B√öSQUEDA: "{query}"
    
    PRODUCTOS FILTRADOS (solo coincidencias exactas):
    {json.dumps(productos_filtrados, indent=2, ensure_ascii=False)}
    
    INSTRUCCIONES:
    1. Enf√≥cate SOLO en estos productos
    2. Destaca diferencias en packaging, tama√±o y precio, tanto bruto como por kilo
    3. Usa este formato:
    
    **Resultados exactos para "{query}"**  
    - [Nombre 1]: [Packaging] de [tama√±o]. [Nota diferencial]  
    - [Nombre 2]: [Packaging] de [tama√±o]. [Nota diferencial]  
    
    **Conclusi√≥n:** Breve comparativa entre las opciones disponibles.
    """
    print("START PROMPT","üî•" * 20)
    print(prompt)
    print("END PROMPT","üî•" * 20)
    respuesta = ollama.chat(
        model=model,
        messages=[{"role": "user", "content": prompt}]
    )
    print("START RESPUESTA","üî•" * 20)
    print(respuesta["message"]["content"])
    print("END RESPUESTA","üî•" * 20)
    return respuesta["message"]["content"].strip()


def clasificar_categoria(
    query: str, 
    opciones: List[str], 
    model: str, 
    nivel: str,
    max_intentos: int = 3
) -> Optional[str]:
    """Clasifica una b√∫squeda en categor√≠as con validaci√≥n y reintentos"""
    query_norm = normalizar_texto(query)
    opciones_norm = {normalizar_texto(o): o for o in opciones}
    
    # Primero intentamos matching exacto o parcial
    for opcion_norm, opcion_real in opciones_norm.items():
        if opcion_norm in query_norm or query_norm in opcion_norm:
            return opcion_real
    
    # Si no hay match directo, usamos el LLM
    for intento in range(max_intentos):
        try:
            prompt = generar_prompt_clasificacion(
                query, 
                list(opciones_norm.values()), 
                nivel
            )
            print("START PROMPT","üî•" * 20)
            print(prompt)
            respuesta = ollama.chat(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                options={"temperature": 0.2}  # Menor creatividad
            )
            print("END PROMPT","üî•" * 20)
            print("START RESPONSE","üî•" * 20)
            print(respuesta["message"]["content"])
            resultado = json.loads(respuesta["message"]["content"])
            print("END RESPONSE","üî•" * 20)
            categoria = resultado[nivel]
            
            # Validamos que la categor√≠a devuelta sea v√°lida
            if categoria in opciones_norm.values():
                return categoria
            
        except (json.JSONDecodeError, KeyError) as e:
            print(f"Error en intento {intento + 1}: {str(e)}")
            continue
    
    return None

def buscar_similares_mejorado(query: str, model: str) -> Tuple[Dict, Dict]:
    """Pipeline mejorado de b√∫squeda que devuelve productos Y categor√≠as"""
    categorias = obtener_categorias_normalizadas()
    
    # Clasificaci√≥n jer√°rquica con validaci√≥n
    l1 = clasificar_categoria(query, list(categorias.keys()), model, "L1")
    if not l1:
        return {}, {}
    
    l2 = clasificar_categoria(query, list(categorias[l1].keys()), model, "L2")
    if not l2:
        return {}, {}
    
    l3 = clasificar_categoria(query, categorias[l1][l2], model, "L3")
    if not l3:
        return {}, {}
    
    productos = obtener_productos_por_categoria(l1, l2, l3)
    categorias_seleccionadas = {
        'L1': l1,
        'L2': l2, 
        'L3': l3
    }
    print(productos,categorias_seleccionadas)
    return productos, categorias_seleccionadas


# ---------------------------
# FUNCIONES UTILITARIAS
# ---------------------------
def contar_tokens(texto):
    """Estima el n√∫mero de tokens en un texto"""
    return len(texto) // 4

def limpiar_respuesta_json(respuesta):
    """Limpia y extrae JSON de respuestas LLM"""
    respuesta_limpia = re.sub(r'<think>.*?</think>', '', respuesta, flags=re.DOTALL).strip()
    return json.loads(respuesta_limpia)

def limpiar_respuesta_texto(respuesta):
    """Limpia texto de marcado innecesario en respuestas LLM"""
    return re.sub(r'<.*?>', '', respuesta).strip()

# ---------------------------
# INTERFAZ DE USUARIO
# ---------------------------
def show():
    st.title("üîç An√°lisis Comparativo de Productos")
    
    model = st.selectbox("Modelo:", MODELS)
    query = st.text_input("¬øQu√© producto buscas?")
    
    if st.button("Analizar") and query:
        with st.spinner("Buscando productos..."):
            productos, categorias = buscar_similares_mejorado(query, model)
            
        # Mostrar categor√≠as seleccionadas
        with st.expander("üìä Categor√≠as seleccionadas"):
            st.write(f"L1: {categorias.get('L1', 'No identificada')}")
            st.write(f"L2: {categorias.get('L2', 'No identificada')}")
            st.write(f"L3: {categorias.get('L3', 'No identificada')}")

        if not productos:
            st.warning("No se encontraron productos. Prueba con t√©rminos m√°s espec√≠ficos.")
            return
        
        # 2. Filtrado inteligente
        with st.spinner("Filtrando productos relevantes..."):
            productos_filtrados = filtrar_productos_relevantes(query, productos, model)  

         # 3. Generar resumen focalizado
            with st.spinner("Preparando recomendaci√≥n..."):
                resumen = generar_resumen_focalizado(query, productos_filtrados, model)
            
        # Mostrar resultados
        st.markdown(resumen)
        
        # Opcional: Mostrar productos descartados
        if len(productos_filtrados) != len(productos):
            with st.expander("‚ö†Ô∏è Productos descartados (misma categor√≠a pero no coinciden)"):
                descartados = {k: v for k, v in productos.items() if k not in productos_filtrados}
                st.json(descartados)

if __name__ == "__main__":
    show()